{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58dc836-625a-4c0a-a840-b23c3ffef10e",
   "metadata": {},
   "source": [
    "# Lineární klasifikace obrázků CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57846d13-17c6-494d-a851-c88e2d363640",
   "metadata": {},
   "source": [
    "Úkolem cvičení je naprogramovat lineární klasifikátor, který bude rozpoznávat objekty z datasetu CIFAR-10.\n",
    "Vstupem je RGB obrázek o rozměrech 32$\\times$32 pixelů a úkolem říci, který z 10 možných objektů (tříd) je na něm zachycen. Možnosti jsou tyto: letadlo, automobil, pták, kočka, jelen, pes, žába, kůň, loď, náklaďák.\n",
    "\n",
    "**Model**\n",
    "- Vstup: $x$, rozměr $N \\times D$, kde $N$ je počet obrázků a $D$ počet číselných hodnot v jednom obrázku\n",
    "  - Každý řádek je jeden obrázek reprezentovaný jako vektor, čísla v rozmezí 0-1.\n",
    "- Parametr váhy (weights): $W$, rozměr $D \\times C$\n",
    "- Parametr bias: $b$, rozměr $C$\n",
    "- Predikované skóre (logity): $s = xW + b$, rozměr $N \\times C$\n",
    "  - Pro každý obrázek predikce $C$ hodnot\n",
    "- Predikovaná třída: $z = \\arg\\max_c s$, rozměr $N$\n",
    "  - Pro každý obrázek vybereme třídu s nejvyšším skóre.\n",
    "\n",
    "**Optimalizace**\n",
    "- Kritérium křížová entropie: $L = \\sum_c{p_c \\cdot \\log q_c}$\n",
    "- Metoda Stochastic Gradient Descent (SGD)\n",
    "  - $W := W - \\gamma \\frac{dL}{dW}$\n",
    "  - $b := b - \\gamma \\frac{dL}{dW}$\n",
    "  - Hyperparametr $\\gamma$ značí rychlost učení (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227fbaf-39c6-4679-bb72-575bc332d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3194cbd-6dbc-4fd8-811a-ab65733b8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # import tests\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ans\n",
    "from tests import test_linear_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f222a54-2876-4c0f-bb22-be3e9391ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile='short')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec2c26-00bc-4e8a-9004-0a0387acb180",
   "metadata": {},
   "source": [
    "# Načtení dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b11da3-defb-4ec3-b66a-c21d6a019f32",
   "metadata": {},
   "source": [
    "Balík torchvision podporuje některé znamé datasety, mezi něž patří i CIFAR-10. Nemusíme tedy data stahovat z internetu manuálně, torchvision za nás vše obstará automaticky. Data uložíme do adresáře `./data`. Všimněme si flagu `train=True`, který říká, že se má načíst trénovací množina datasetu CIFAR-10 (soubory `data_batch_*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464e66e-b25f-4176-b075-795c328bfcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df06adc-9a6e-47fe-8448-dcc981218570",
   "metadata": {},
   "source": [
    "Validovat budeme na zbylých 10000 obrázcích. Získáme je nastavením `train=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5814d-f421-482b-b059-495b06552899",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb2043-3188-4be7-a6a2-21790c59273d",
   "metadata": {},
   "source": [
    "Seznam tříd je uložen v atributu `.classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e1ec4-ba6e-4c5f-a02a-853c54a35fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13b57e-1d86-4f69-9b25-b7b3d90c207d",
   "metadata": {},
   "source": [
    "Objekt třídy `torchvision.datasets.cifar.CIFAR10` se chová podobně jako pythonovský `list` s tím, že každý jeho prvek je dvojice (obrázek, třída)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f811d-18ec-4668-b3a1-45548c363f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2810dd-fde7-4fa2-80de-85ccfbc2b0e7",
   "metadata": {},
   "source": [
    "Jak vidíme, 6. prvek datasetu je *dvojice* (`tuple`) sestávající z obrázku a jeho indexu třídy (label, target).\n",
    "\n",
    "- Obrázek je defaultně navrácen jako typ `Image` knihovny Pillow (Python Imaging Library, PIL).\n",
    "\n",
    "- Target je číslo typu `int` označující jednu ze tříd v atributu `.classes`.\n",
    "\n",
    "Všechny obrázky CIFAR-10 datasetu jsou uloženy v atributu `.data`, což je 4D `numpy.ndarray` typu `np.uint8`. První dimenze odpovídá jednotlivým obrázkům, další pak řádkům, sloupcům a kanálům (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9d30c-fb14-4c6d-88e4-f09b9f609f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset.data), train_dataset.data.shape, train_dataset.data.dtype, train_dataset.data.min(), train_dataset.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8eed48-d5bb-4d3b-b3e0-6789c995de0f",
   "metadata": {},
   "source": [
    "Podobně všechny targety jsou uložny v `.targets`, což je `list` o délce počtu obrázků, přičemž každý target číslo typu `int` v rozmezí 0-9, kde 0 značí letadlo (airplane), 1 značí automobil (automobile) atd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e13aa-0227-46ea-be18-e65e0e18e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset.targets), len(train_dataset.targets), type(train_dataset.targets[0]), min(train_dataset.targets), max(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113da300-9165-4031-b589-abce0534934b",
   "metadata": {},
   "source": [
    "Pro lepší představu si vykreslíme sloupec 10 obrázků pro každou z 10 tříd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7e46f-e14d-4155-92de-de34011be9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, cls in enumerate(train_dataset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(train_dataset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(train_dataset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b313d57-3df8-4fb7-8d60-5c4fe7d5a56e",
   "metadata": {},
   "source": [
    "# Načítání dat po dávkách"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487954a-4c9e-4b12-b573-077e745337dd",
   "metadata": {},
   "source": [
    "Prvním úkolem bude implementovat načítání dat po dávkách, na kterých se bude klasifikátor učit. Funkcionalita je implementovaná třídou `ans.data.BatchLoader` a nachází se v souboru `ans/data.py`. Třída implementuje metodu `__iter__` a je tedy možné ji použít jako zdroj např. pro `for` cyklus následujícím způsobem:\n",
    "``` python\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),  # input images, shape (50000, 32, 32, 3)\n",
    "    torch.tensor(train_dataset.targets),  # targets, shape (50000,)\n",
    "    batch_size=100,\n",
    "    shuffle=True  # return the data in random order\n",
    ")\n",
    "for inputs, targets in train_loader:\n",
    "    # inputs ... shape (100, 32, 32, 3)\n",
    "    # targets ... shape (100,)\n",
    "    ...\n",
    "```\n",
    "**Úkol: implementujte metodu `__iter__` třídy `ans.data.BatchLoader`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72499837-36b6-4b15-baa5-db3d8131e1f7",
   "metadata": {},
   "source": [
    "Implementaci lze zkontrolovat připravenými unit testy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661712f3-3199-4c93-8ad9-616562e69c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestBatchLoader.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900a6c3-908b-4b35-90e8-4e6b54df63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=5,\n",
    "    shuffle=True\n",
    ")\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8985c-fce9-4b65-b2fd-d2ff7dafa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "print(type(inputs), inputs.shape, inputs.dtype, inputs.min(), inputs.max())\n",
    "print(type(targets), targets.shape, targets.dtype, targets.min(), targets.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2457f-76eb-46c1-b244-db40cc83e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=5,\n",
    "    shuffle=False\n",
    ")\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271b447-eb0e-4b64-89a6-429ef762e489",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230341e-d228-483b-a44f-71823c40100c",
   "metadata": {},
   "source": [
    "Data jsou celočiselného typu `torch.uint8`, což jsou čísla v rozmezí 0-255. Pro lepší numerické vlastnosti data převedeme do rozsahu 0-1 a datového typu `torch.float32`, který je pro PyTorch výchozí. Operaci provedeme jednoduchým vydělením max. hodnotou 255. Zároveň obrázky přetvarujeme do vektoru, takže výstup bude mít rozměr (batch_size, počet_pixelů). Celé předzpracování bude implementovat funkce `preprocess`, kterou budeme volat pro každou dávku po jejím načtení z `BatchLoader`u. Normalizovat budeme pouze obrázky, s targety nic dělat nebudeme.\n",
    "\n",
    "**Úkol: implementuje funkci `preprocess`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1507c-2586-4955-92ed-3e4c1e88609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: n-dimensional tensor with first dimension of size num_inputs\n",
    "    Returns:\n",
    "        outputs: 2-dimensional tensor; shape (num_inputs, num_features), dtype float32\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2db5c4-8a24-48e0-841d-49238e224021",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestPreprocess.eval(preprocess_fn=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbe173-2a8f-4e46-a364-00bce057b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_prep = preprocess(inputs)\n",
    "inputs_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336171da-83e0-4ba9-b951-d9c260ca4896",
   "metadata": {},
   "source": [
    "# Inicializace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4bdb7-b022-4314-93fb-6107472c7027",
   "metadata": {},
   "source": [
    "Váhovou matici $W$ klasifikátoru inicializujeme na náhodné hodnoty s normálním rozdělením a malou standardní odchylkou. Bias inicializujeme vektor nul s odpovídajícím rozměrem. Inicializaci bude provádět funkce `init_params`, která převezme rozměry a požadovanou odchylku (parametr `multiplier`) a vrátí dvojici (weight, bias).\n",
    "\n",
    "Pozn.: nezapomínejme, že obrázky jsou uloženy *po řádcích* a náš model má podobu $s = xW + b$. Od toho se odvíjejí rozměry $W$ a $b$.\n",
    "\n",
    "**Úkol: implementuje funkci `init_params`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b9d3e-137f-410b-bcbd-3a701fbf8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_dim: int, output_dim: int, multiplier: float = 1e-2) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dim: size of one input\n",
    "        output_dim: size of one output\n",
    "        multiplier: standard deviation of weight\n",
    "    Returns:\n",
    "        weight, bias\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "\n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779f2b2-9afc-4c22-9473-ba5e8d8f6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestInit.eval(init_params_fn=init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdec4a-ee27-4246-8c6a-4305cfef3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = init_params(...)\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2873e-6b7e-4ed3-b0d1-3ec0778a459a",
   "metadata": {},
   "source": [
    "# Výpočet lineárních skóre (logitů)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218799ae-1615-4d76-861a-592df7065013",
   "metadata": {},
   "source": [
    "Nyní vypočteme lineární skóre (logity) jako\n",
    "$$s_n = x_nW + b$$\n",
    "kde\n",
    "- $s_n$ je vektor skóre pro $n$-tý vzorek (obrázek) $x_n$ a každou z $C$ tříd\n",
    "- $x_n$ je $n$-tý vzorek (obrázek) v dávce reprezentovaný jako (řádkový) vektor\n",
    "- $W$ je matice vah klasifikátoru\n",
    "- $b$ je bias klasifikátoru\n",
    "\n",
    "Výpočet bude zajišťovat funkce `calc_linear_scores`\n",
    "\n",
    "**Úkol: implementuje funkci `calc_linear_scores`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897fffb1-0adb-452b-b45d-ca22a43247bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_linear_scores(inputs: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: shape (num_samples, num_features)\n",
    "        weight: shape (num_features, num_classes)\n",
    "        bias: shape (num_classes,)\n",
    "    Returns:\n",
    "        scores: shape (num_samples, num_classes)\n",
    "    \"\"\"\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c50d73-7e1c-4335-a255-29efa998761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestCalcLinearScores.eval(calc_linear_scores_fn=calc_linear_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ea5c1-c445-43f5-8b24-aaf8938dccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = calc_linear_scores(inputs_prep, weight, bias)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f28748-2d2c-4d69-965d-0d4d69759aa3",
   "metadata": {},
   "source": [
    "# Kritérium: softmax cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883fbd8-ae91-4434-afa0-76a231346c3c",
   "metadata": {},
   "source": [
    "Výstupní pravděpodobnost $c$-té třídy $q_{nc}$ predikovaná klasifikátorem pro $x_n$ získáme aplikací funkce softmax na skóre $s$\n",
    "$$q_{nc} = \\frac{\\exp{s_{nc}}}{\\sum_{i=1}^{C}{\\exp{s_{ni}}}}, c=1,\\ldots,C$$\n",
    "kde\n",
    "- $s_{nj}$ je predikované skóre $n$-tého vzorku dávky třídy $j$\n",
    "\n",
    "Klasifikátor budeme trénovat optimalizací křížové entropie mezi predikovanými $q_{nc}$ a skutečnými pravděpodobnostmi $p_{nc}$\n",
    "$$L_n = \\sum_c{p_{nc} \\log q_{nc}}$$\n",
    "kde\n",
    "- $L_n$ je hodnota kritéria pro $n$-tý vzorek $x_n$ dávky $x$\n",
    "\n",
    "Jelikož pro každý obrázek známe, který objekt je na něm zachycen, skutečné diskrétní rozdělení pravděpodobnosti $p_n=[p_{n1},\\ldots,p_{nC}]$ má pouze jednu hodnotu $p_{nc}=1$ a to správnou třídu $c=y_n$; ostatní $p_{nc}=0, c \\ne y_n$ jsou nulové. Jde tedy o tzv. one hot vektor. Sloučením softmaxu a odstranění nulových členů ve vztahu pro výpočet entropie získáme\n",
    "$$L_n = \\log q_{ny_n} = \\log\\frac{\\exp{s_{ny_n}}}{\\sum_{c=1}^{C}{\\exp{s_{nc}}}} = -s_{ny_n} + \\log\\sum_c\\exp s_{nc}$$\n",
    "Loss tedy můžeme počítat přímo z lineárních skóre (logitů), což s sebou zároveň přináší výhodu modularity, protože později takto bude možné kritérium jednoduše vyměnit např. za hinge loss a namísto logistické regrese tak trénovat klasifikátor SVM. Kritérium bude počítat funkce `softmax_cross_entropy`.\n",
    "\n",
    "**Úkol: implementujte funkci `softmax_cross_entropy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5123954-28bd-42ec-a7d9-fe69b25be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        loss: averare cross entropy on the batch; tensor containing single number (scalar), e.g. \"tensor(2.23)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85889837-2623-4a64-aedf-3a3ee2a53267",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestSoftmaxCrossEntropy.eval(softmax_cross_entropy_fn=softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00a48f-6381-4069-92b5-92ea1521db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = softmax_cross_entropy(logits, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbd2a0-d028-40df-a11c-3d81718df079",
   "metadata": {},
   "source": [
    "# Úspěšnost: accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f897b-6a82-436c-b4e8-899b66e7b9b0",
   "metadata": {},
   "source": [
    "Kromě lossu budeme pro lepší orientaci měřit i přesnost (accuracy), byť tuto veličinu nebudeme přímo optimalizovat.\n",
    "\n",
    "**Úkol: implementujte funkci `accuracy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14507d-43a6-4be6-89f5-c473620dcdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        acc: averare accuracy on the batch; tensor containing single number (scalar), e.g. \"tensor(0.364)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ce42d-db54-43fb-bc40-aa776d5b5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestAccuracy.eval(accuracy_fn=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc1bed-4a6f-41cf-99bc-96f6af90defd",
   "metadata": {},
   "source": [
    "# Gradient na parametry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6188041-315a-4649-b782-f64ef8f0d407",
   "metadata": {},
   "source": [
    "Optimalizace lossu $L$ bude probíhat stochastickou metodou nejvějtšího spádu (Stochastic Gradient Descent, SGD). K tomu potřebujeme znát gradient na jednotlivé parametry, na kterých $L$ závisí:\n",
    "\n",
    "Gradient na $c$-tý řádek matice $W$:\n",
    "$$\\frac{\\partial L_n}{\\partial w_c} = \\frac{1}{N}(q_{nc} - p_{nc})x_n$$\n",
    "kde\n",
    "- $x_n$ $n$-tý vzorek dávky\n",
    "- $q_{nc}$ je pravděpodobnost $c$-té třídy predikovaná pro $x_n$\n",
    "- $p_{nc}$ je cílová požadovaná pravděpodobnost pro $x_n$\n",
    "- $N$ je počet vzorků $x_n$ v dávce $x$.\n",
    "\n",
    "Gradient na $c$-tý prvek biasu:\n",
    "$$\\frac{\\partial L}{\\partial b_c} = \\frac{1}{N}(q_{nc} - p_{nc})$$\n",
    "\n",
    "Oba gradienty bude vracet funkce `softmax_cross_entropy_gradients`, přičemž vstupem jí budou potřebné proměnné, tj. $x$, $q$ a $p$.\n",
    "\n",
    "**Úkol: implementuje funkci `softmax_cross_entropy_gradients`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9902f-cef4-4ce0-aacf-8cfe226b4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_gradients(\n",
    "    inputs: torch.Tensor,\n",
    "    logits: torch.Tensor,\n",
    "    targets: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d723c3-4e87-4b49-841a-b4f88d609763",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestSoftmaxCrossEntropyGradients.eval(softmax_cross_entropy_gradients_fn=softmax_cross_entropy_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad41262-2023-4601-aa5f-e850e3b5b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dweight, dbias = softmax_cross_entropy_gradients(inputs_prep, logits, targets)\n",
    "dweight, dbias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b13aec-a62b-4e03-9ba0-3828a69e59a2",
   "metadata": {},
   "source": [
    "# Update parametrů\n",
    "\n",
    "Update bude probíhat metodou největšího spádu (Gradient Descent), tj. od aktuáního odhadu parametrů $\\theta$ odečteme gradient $\\frac{dL}{\\theta}$ přeškálovaný krokem $\\gamma$:\n",
    "\n",
    "$\\theta := \\theta - \\gamma \\frac{dL}{\\theta}$\n",
    "\n",
    "Update implementujeme jako funkci, která převezme parametr, gradient na něj a krok učení $\\gamma$ a parametr updatuje. Nebude přitom bytečně vytvářet jeho kopii, vše proběhne modifikací původního tensoru, anglicky tzv. inplace.\n",
    "\n",
    "**Úkol: implementuje funkci `update_param_inplace`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52661bec-869f-491f-a379-0029dc415d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_param_inplace(param: torch.Tensor, dparam: torch.Tensor, learning_rate: float) -> None:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94f77b-1e63-4971-801b-aee680c8686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestUpdateParamInplace.eval(update_param_inplace_fn=update_param_inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8996b7f-7704-4c02-8fab-e66fd153d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e87d0-534c-4594-b6ef-97ff9a02fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_param_inplace(weight, dweight, 0.1)\n",
    "update_param_inplace(bias, dbias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9e8df-c880-4be6-aba3-020acb374ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539151d0-9250-43dd-b9f5-18103bbf05cf",
   "metadata": {},
   "source": [
    "# Spojení všech kroků dohromady: funkce `train_step` a `val_step`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70406c-aa2c-4b7c-ad6c-b6dac13504ab",
   "metadata": {},
   "source": [
    "Nyní spojíme všechny kroky do jedné funkce `train_step_softmax`, která převezme dávku vzorků, aktuální parametry klasifikátoru a hyperparametr krok učení a provede jeden krok směrem k mnimializaci křížové entropie na dávce. Funkce vrátí hodnotu lossu a přesnosti (accuracy) dosaženou na dávce.\n",
    "\n",
    "**Úkol: implementuje funkci `train_step_softmax`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fab2ee-e970-4f1d-bd33-d042099378fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_softmax(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    learning_rate: float = 1e-3\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21bf56-d65a-4a0d-8c69-9b49c7ee7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestTrainStepSoftmax.eval(train_step_softmax_fn=train_step_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f07f7-4099-4676-9849-d13dacc01ab7",
   "metadata": {},
   "source": [
    "**Úkol: implementuje funkci `val_step`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7d3e4-6a03-4756-8a79-0c07e12b89e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], tuple[float, float]]  # e.g. softmax_cross_entropy\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a987660-4b95-4cae-8d1e-869157e4ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestValStep.eval(val_step_fn=val_step, loss_fn=softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703e9c8-0f27-468d-8bca-eea789eab230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    loader: ans.data.BatchLoader,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], tuple[float, float]]  # e.g. softmax_cross_entropy\n",
    ") -> tuple[float, float]:\n",
    "    total_loss = 0.\n",
    "    total_acc = 0.\n",
    "    for inputs, targets in loader:\n",
    "        loss, acc = val_step(inputs, targets, weight, bias, loss_fn)\n",
    "        total_loss += loss\n",
    "        total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e4833-7041-4975-ab83-b03798609d62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "learning_rate = ...\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=...,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=...,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "weight, bias = init_params(...)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, weight, bias, softmax_cross_entropy)\n",
    "val_loss, val_acc = validate(val_loader, weight, bias, softmax_cross_entropy)\n",
    "print(f\"after init: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step_softmax(inputs, targets, weight, bias, learning_rate=learning_rate)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    # train_loss, train_acc = validate(train_loader, weight, bias, softmax_cross_entropy)\n",
    "    val_loss, val_acc = validate(val_loader, weight, bias, softmax_cross_entropy)\n",
    "    \n",
    "    # print\n",
    "    print(f\"epoch {epoch + 1}: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ad58e-6aba-4a3d-a8e0-edd209f53a58",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561af5b-f5f4-4390-a486-5556944c8f4e",
   "metadata": {},
   "source": [
    "SVM je softmaxu velmi podobné. Z pohledu neuronových sítí se liší pouze způsobem výpočtu lossu - místo cross entropy použijeme hinge loss:\n",
    "$$L_n = \\sum_{c\\ne y_n}\\max(0, 1 + s_{nc} - s_{ny})$$\n",
    "kde:\n",
    "- $y_n$ je správný index třídy na vzorku (obrázku) $x_n$\n",
    "- $s_{ni}$ je skóre (logity) predikované lineárním klasifikátorem pro $n$-tý obrázek a $i$-tou třídu.\n",
    "\n",
    "Gradient na váhy pak je\n",
    "$$\\frac{\\partial L_n}{\\partial w_{y_n}} = -\\sum_{c\\ne y_n}\\boldsymbol{1}(1 + s_{nc} - s_{ny} > 0)x_n$$\n",
    "$$\\frac{\\partial L_n}{\\partial w_{c\\ne y_n}} = \\boldsymbol{1}(1 + s_c - s_y > 0)x_n$$\n",
    "a pro biasy podobně, pouze bez násobení $x_n$ (na konci).\n",
    "\n",
    "**Úkol: implementuje funkce `hinge_loss`, `hinge_loss_gradients` a `train_step_svm`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e8cb8-3823-4fff-bfc9-092841792a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output from linear classifier, i.e. the pre-softmax logits; shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        loss: averare Weston-Watkins hinge loss on the batch; tensor containing single number (scalar), e.g. \"tensor(2.374)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588ea1e-3aeb-4c38-a874-92ee52c29bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestHingeLoss.eval(hinge_loss_fn=hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ee48c-6fc4-456b-a98e-85c74efbd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_gradients(\n",
    "    inputs: torch.Tensor,\n",
    "    scores: torch.Tensor,\n",
    "    targets: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35c116-e903-4744-8746-18051bd05dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestHingeLossGradients.eval(hinge_loss_gradients_fn=hinge_loss_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06028d3c-43a9-4b85-b528-031630191ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_svm(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    learning_rate: float = 1e-3\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f53866-fc54-44a5-bc59-61838a49897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestTrainStepSVM.eval(train_step_svm_fn=train_step_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84bdda-662e-49da-949f-df2c20f1caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = ...\n",
    "learning_rate = ...\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=...,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=...,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "weight, bias = init_params(...)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, weight, bias, hinge_loss)\n",
    "val_loss, val_acc = validate(val_loader, weight, bias, hinge_loss)\n",
    "print(f\"after init: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step_svm(inputs, targets, weight, bias, learning_rate=learning_rate)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    # train_loss, train_acc = validate(train_loader, weight, bias, hinge_loss)\n",
    "    val_loss, val_acc = validate(val_loader, weight, bias, hinge_loss)\n",
    "    \n",
    "    # print\n",
    "    print(f\"epoch {epoch + 1}: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ans22",
   "language": "python",
   "name": "ans22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
